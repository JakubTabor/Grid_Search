# Now I gonna build a Neural Network to deal with this task
# I gonna search for the best parameters and write plot function to plot on graph all results
# So I define my function, which will plot on graph history of my model, I will plot it with "subplots"
# First I definne "loss" of my model from history, then "validation loss" during the training
# Then named (x axis and y axis) as (Epoch and Binary crossentropy)
# Secound plot will be with (accuracy and validation accuracy) and also I named (x axis and y axis) as (Epoch and Accuracy)
# Now when I have defined plot function I import tensorflow to build my model
# I create function "train_model" and pass inside (X_train, y_train for training)
# I pass also "num_nodes", so (neurons to define them later), I do exactly this same with (dropout_prob, to pass numbers later) 
# And also I pass "learning rate" to specify later values, as well as "batch size" and "epochs"
# Then I specify my model, it will be normal Neural network, so I call tensorflow keras Sequential model
# But instead of passing exact values I gonna pass previous defined variables to specify them later in parameters training
# I pass first "Dense layer" and put inside my variable responsible for neurons, then activation and shape, it will be ten classes in my dataset
# Next I pass "Dropout layer" and put inside "variavle dropout_prob", which correspond for dropping neurons 
# Then I pass another "Dense layer", same as previous and after also "Dropout layer"
# And I pass last Output layer" with one neuron and activation "sigmoid"
# Now I compile my model with optimizer as "adam" "tf.keras.optimizers.Adam" and add variable "lr" to specify later numbers for learning rate
# And loss will be "binary_crossentropy" for my binary output, metrics as "accuracy"
# I save training process of my model as history to plot it later on graph
# I use "X_train and y_train" as training data, than pass "epochs variable", I also pass "batch_size  variable"
# Then I set "validation_split" at (0.2), now its time to set "hyperparameters"
# I set epochs to (50), then I make for loop for "hyperparameters", first I set some numbers for "num_nodes"
# Next I set some numbers for "dropout_prob", then for learning rate and for batch size, there are the most popular options
# I set print option for every parameter, so it gonna show all parameters under the graph
# Then I make model training and call plot function on history variable of my model
# I also make evaluation of my model on (X_valid and y_valid), I save it as "val_loss"
# And in the end i put condition for my hyperparameter loop (if val_loss variable is less than least val_loss) it will become it
# This variable "least_loss_model" is equal to "model"
# And then all stars, so i get graphs with training and evaluation, below all parameters
# I can see that all parameters are changing after every epoch and accuracy is around 86%
# Now I can pick the best parameters, which is close to 88%
# I also make predictions on X_test and reshaped them to accurate range for "classification_report"
